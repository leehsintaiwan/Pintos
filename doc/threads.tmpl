            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sipan Petrosyan <sipan.petrosyan20@imperial.ac.uk>
Vincent Lee <vincent.lee20@imperial.ac.uk>
Jamie Todd <jamie.todd20@imperial.ac.uk>
Joel Chu <joel.chu20@imperial.ac.uk>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the Pintos documentation, course text, lecture notes 
>> and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

struct list donators;                 /* List of donator threads */
struct list_elem donator_elem;        /* List element for donators list */
struct lock *wait_lock;               /* The lock causing the thread to wait */

>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) lock, (ii) semaphore, or (iii) condition variable?

For all three synchronization primitives, we store the list of waiters in the relevant semaphore.
We wrote a list less function to compare the thread priorities,
and used list_max to find and wake up the highest priorty waiting thread.

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

When lock_acquire() is called and the lock is already acquired by another thread,
we add the current thread to the list of donators to the lock holder.
To handle nested donation, everytime thread_get_priority is called, it recursively
goes through each list of donators and returns the highest priority donated to each thread.

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

First we find the highest priority thread that is waiting for this lock.
Then we remove the highest priority thread from the list of threads waiting for this lock.
Next we go through the list of donators assigned to the original lock holder,
and donate each of the threads who is waiting for this lock to the new highest priority thread.

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

In order to avoid race conditions in thread_set_priority(), we used the priority_lock variable. 
We acquired the lock prior to modifying any thread priority values, iterating through the list of threads, or yielding any threads.
Only after all threads have been iterated through do we release priority_lock.

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?

We chose to recursively get the highest priority from the list of donator threads
in thread_get_priority() and only set the current thread's priority in 
thread_set_priority() rather than vice versa. This way when releasing a lock, 
we don't need to recursively update all the nested priority donations while 
keeping track of the initial priorities of each thread.

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

int nice;                                     /* Nice value of a thread */
int recent_cpu;                               /* recent_cpu value of a thread */

#define MULTIPLIER 100                        /* Factor for calculating recent_cpu and load_avg */
int32_t load_avg = INTEGER_TO_FIXED_POINT(0); /* system load average; most recent load_avg value obtained from thread_get_load_avg() */

---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      4   0   0  62  61  59     A  
 8      8   0   0  61  61  59     A  
12      12  0   0  60  61  59     B        
16      12  4   0  60  60  59     B  
20      12  8   0  60  59  59     A  
24      16  8   0  59  59  59     A
28      20  8   0  58  59  59     B
32      20  12  0  58  58  59     C
36      20  12  4  58  58  58     C

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?

There were ambiguities in the table for which thread to run next when multiple threads shared the highest priority. 
We resolved this issue by choosing the already running thread if applicable, otherwise choosing the thread with the lowest niceness.

Regarding recent_cpu and priority values, there weren't any ambiguities assuming that thread A was not running prior to tick 0, however, 
if the table extended to over 100 ticks, or if thread A was running prior to tick 0, then there would be ambiguities for when to recalculate 
load_avg and recent_cpu of each thread.

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.

We used one list instead of 64 queues because it takes up less space on the stack. However, it is less efficient to acquire threads with only one list.
An alternative solution could be to sort the list of threads by priority each time the priorities are changed so we do not need to iterate though all of the threads every time to obtain the thread with the highest priority.
This would have saved time scheduling threads.
