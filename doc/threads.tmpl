            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sipan Petrosyan <sipan.petrosyan20@imperial.ac.uk>
Vincent Lee <vincent.lee20@imperial.ac.uk>
Jamie Todd <jamie.todd20@imperial.ac.uk>
Joel Chu <joel.chu20@imperial.ac.uk>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the Pintos documentation, course text, lecture notes 
>> and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

struct list donators;                         /* List of donator threads */
struct list_elem donator_elem;                /* List element for donators list */
struct lock *wait_lock;                       /* The lock causing the thread to wait */

>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) lock, (ii) semaphore, or (iii) condition variable?

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

In order to avoid race conditions in thread_set_priority(), we used the priority_lock variable. 
We acquired the lock prior to modifying any thread priority values, iterating through the list of threads, or yielding any threads.
Only after all threads have been iterated through do we release priority_lock.

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

int nice;                                     /* Nice value of a thread */
int recent_cpu;                               /* recent_cpu value of a thread */

#define MULTIPLIER 100                        /* Factor for calculating recent_cpu and load_avg */
int32_t load_avg = INTEGER_TO_FIXED_POINT(0); /* system load average; most recent load_avg value obtained from thread_get_load_avg() */

---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      4   0   0  62  61  59     A  
 8      8   0   0  61  61  59     A  
12      12  0   0  60  61  59     B        
16      12  4   0  60  60  59     B  
20      12  8   0  60  59  59     A  
24      16  8   0  59  59  59     A
28      20  8   0  58  59  59     B
32      20  12  0  58  58  59     C
36      20  12  4  58  58  58     C

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?

There were ambiguities in the table for which thread to run next when multiple threads shared the highest priority. 
We resolved this issue by choosing the already running thread if applicable, otherwise choosing the thread with the lowest niceness.

Regarding recent_cpu and priority values, there weren't any ambiguities assuming that thread A was not running prior to tick 0, however, 
if the table extended to over 100 ticks, or if thread A was running prior to tick 0, then there would be ambiguities for when to recalculate 
load_avg and recent_cpu of each thread.

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.

We used one list instead of 64 queues because it takes up less space on the stack. However, it is slower to get threads with one list.
We could have sorted the list by priority each time priorities are changed so we do not need to use a for loop every time to get the thread with highest priority.
